import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import folium
from folium.features import GeoJsonTooltip
from streamlit_folium import st_folium
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans
from sklearn.impute import SimpleImputer
from sklearn.metrics import silhouette_score, silhouette_samples

from data_loader import get_clean_data, load_shapefile
from utils import normalize_county, COUNTY_CODE_TO_NAME, ordinal_encode_nivel, binary_encode_mediu

# --- Configurare paginÄƒ ---
st.set_page_config(page_title="AnalizÄƒ clusterizare", page_icon="ğŸ“Š", layout="wide")

# --- CSS pentru grafice mici ---
st.markdown(
    '''
    <style>
      .chart-container { display: flex; justify-content: center; }
      .small-chart { width: 100%; max-width: 350px; }
    </style>
    ''', unsafe_allow_html=True)

# --- ÃncÄƒrcare date ---
@st.cache_data(show_spinner="Se Ã®ncarcÄƒ È™i curÄƒÈ›Äƒ datele...")
def load_data():
    return get_clean_data()

df = load_data()

# --- Previzualizare iniÈ›ialÄƒ & sumar curÄƒÈ›are ---
st.title("ğŸ“Š AnalizÄƒ clusterizare pe judeÈ›e")
with st.expander("Previzualizare date curÄƒÈ›ate & Sumar curÄƒÈ›are", expanded=False):
    st.dataframe(df.head(5), use_container_width=True)
    st.markdown(f"**ÃnregistrÄƒri:** {df.shape[0]:,} &nbsp;|&nbsp; **Caracteristici:** {df.shape[1]}")
    st.markdown(
        """
        **PaÈ™i de curÄƒÈ›are:**
        - Valorile numerice lipsÄƒ au fost completate cu mediana; valorile categorice cu 'Necunoscut'.
        - Denumirile coloanelor standardizate; coloane irelevante eliminate.
        - 'Nivel' codificat ordinal; 'Mediu' codificat binar.
        - JudeÈ›ele normalizate pentru coerenÈ›Äƒ si reprezentarea pe harta.
        """
    )

# --- Normalizare judeÈ›e & codificare ---
st.markdown("## ğŸ—ºï¸ Normalizare judeÈ›e & Codificare")
if 'Judet' not in df.columns:
    st.error("LipsÄƒ coloana 'Judet'.")
    st.stop()

def normalize_judet(x):
    if pd.isna(x):
        return np.nan
    key = str(x).upper().strip()
    name = COUNTY_CODE_TO_NAME.get(key, key)
    return normalize_county(name)

# Aplicare normalizare
# MapeazÄƒ 'Judet' iniÈ›ial la 'county_clean'
df['county_clean'] = df['Judet'].map(normalize_judet)
# EliminÄƒ rÃ¢ndurile fÄƒrÄƒ normalizare
df = df.dropna(subset=['county_clean'])
# AfiÈ™eazÄƒ numÄƒrul unic
st.info(f"S-au normalizat {df['county_clean'].nunique()} judeÈ›e.")

# Codificare 'Nivel' & 'Mediu'
st.markdown("**Codificare 'Nivel' & 'Mediu'**")
if 'Nivel' in df.columns:
    df['Nivel_Encoded'] = df['Nivel'].map(ordinal_encode_nivel)
if 'Mediu' in df.columns:
    df['Mediu_Encoded'] = df['Mediu'].map(binary_encode_mediu)

# --- Pasul 1: Selectare caracteristici & agregare ---
st.markdown("## ğŸ”¢ Pasul 1: Selectare caracteristici & Agregare")
possible = df.select_dtypes(include='number').columns.tolist()
exclude = ['_id','cod_unitate_pj','cod_unitate_plan','period','elevi_exist_asoc']
avail = [c for c in possible if c not in exclude]
defaults = [c for c in [
    'Numarul claselor existente','Numarul elevilor existenti',
    'Numarul claselor propuse','Numarul elevilor propusi',
    'Clase exist anterior-formatiun','Elevi exist anterior-asoc',
    'Nivel_Encoded','Mediu_Encoded'
] if c in avail]
features = st.multiselect(
    "SelecteazÄƒ caracteristici numerice pentru clusterizare:",
    options=avail,
    default=defaults
)
if not features:
    st.error("SelecteazÄƒ cel puÈ›in o caracteristicÄƒ pentru a continua.")
    st.stop()

agg = df.groupby('county_clean')[features].mean().reset_index()
st.dataframe(agg.head(5), use_container_width=True)
st.info("Tabelul afiÈ™eazÄƒ valorile medii ale caracteristicilor selectate per judeÈ›.")

# --- Pasul 2: Vizualizare PCA ---
st.markdown("## âœ¨ Pasul 2: Vizualizare PCA")
st.markdown(
    """
    **Ce este PCA?** Analiza componentelor principale reduce dimensiunea datelor transformÃ¢nd caracteristicile Ã®n componente necorelate.

    **De ce 90% varianÈ›Äƒ?** PÄƒstreazÄƒ componentele care explicÄƒ 90% din varianÈ›Äƒ pentru a menÈ›ine informaÈ›ia.
    """
)
X = agg.set_index('county_clean')[features]
X_imp = pd.DataFrame(SimpleImputer(strategy='median').fit_transform(X), columns=features, index=X.index)
X_scaled = StandardScaler().fit_transform(X_imp)

pca_full = PCA().fit(X_scaled)
cumvar = np.cumsum(pca_full.explained_variance_ratio_)
opt_n = min(max(2, int(np.searchsorted(cumvar, 0.9) + 1)), X_scaled.shape[1])
n_max = min(X_scaled.shape[1], 10)
n_comp = st.slider(
    "Alege numÄƒrul de componente PCA:",
    min_value=2,
    max_value=n_max,
    value=opt_n,
    help="SelecteazÄƒ componente pentru ~90% varianÈ›Äƒ"
)
pca = PCA(n_components=n_comp, random_state=42)
X_pca = pca.fit_transform(X_scaled)
exp = pca.explained_variance_ratio_
cumexp = np.cumsum(exp)

col1, col2 = st.columns(2)
with col1:
    st.markdown("**VarianÈ›Äƒ explicatÄƒ**")
    fig1, ax1 = plt.subplots(figsize=(4,2.5))
    ax1.bar(range(1, n_comp+1), exp)
    ax1.step(range(1, n_comp+1), cumexp, where='mid', color='red')
    ax1.axhline(0.9, ls='--', color='gray')
    ax1.set_xticks(range(1, n_comp+1))
    st.pyplot(fig1)
    st.info("Barele aratÄƒ varianÈ›a per componentÄƒ; linia roÈ™ie este cumulativÄƒ 90%.")
with col2:
    st.markdown("**Scatter PC1 vs PC2**")
    fig2, ax2 = plt.subplots(figsize=(4,2.5))
    ax2.scatter(X_pca[:,0], X_pca[:,1], alpha=0.7)
    ax2.set_xlabel('PC1')
    ax2.set_ylabel('PC2')
    st.pyplot(fig2)
    st.info("Scatter al judeÈ›elor pe primele douÄƒ componente PCA.")

st.markdown(
    """
    **Interpretare componente principale:**
    - **PC1** reflectÄƒ scara: judeÈ›e cu numÄƒr mare de clase/elevi.
    - **PC2** contrasteazÄƒ propuse vs existente.
    - **PC3** (dacÄƒ e selectatÄƒ) reflectÄƒ diferenÈ›e Ã®ntre elevii anterioari-asociaÈ›i È™i Ã®nscrierile noi.
    """
)

# --- Pasul 3: NumÄƒr optim de clustere ---
st.markdown("## ğŸ“ˆ Pasul 3: NumÄƒr optim de clustere")
st.markdown(
    """
    **Ce este K?** NumÄƒrul de clustere.
    
    **Metoda cotului:** PloteazÄƒ inerÈ›ia vs K; cautÄƒ punctul de 'cot'.
    **Scor Silhouette:** MÄƒsoarÄƒ separarea clusterelor; aproape de 1 e mai bine.
    """
)
ks = list(range(2, min(15, X_pca.shape[0]) + 1))
def compute_metrics(data, ks):
    inertias, sils = [], []
    for k in ks:
        km = KMeans(n_clusters=k, random_state=42, n_init=10).fit(data)
        inertias.append(km.inertia_)
        sils.append(silhouette_score(data, km.labels_))
    return pd.DataFrame({'K': ks, 'Inertia': inertias, 'Silhouette': sils})
metrics = compute_metrics(X_pca, ks)

col3, col4 = st.columns(2)
with col3:
    st.markdown("**Metoda cotului**")
    fig3, ax3 = plt.subplots(figsize=(4,2.5))
    ax3.plot(metrics['K'], metrics['Inertia'], '-o')
    ax3.set_xticks(ks)
    ax3.set_xlabel('K')
    ax3.set_ylabel('InerÈ›ia')
    st.pyplot(fig3)
    st.info("InerÈ›ia vs K; cotul aratÄƒ randamente descrescÄƒtoare.")
with col4:
    st.markdown("**Scoruri Silhouette**")
    fig4, ax4 = plt.subplots(figsize=(4,2.5))
    ax4.plot(metrics['K'], metrics['Silhouette'], '-o')
    ax4.set_xticks(ks)
    ax4.set_xlabel('K')
    ax4.set_ylabel('Silhouette')
    st.pyplot(fig4)
    st.info("Silhouette vs K; mai mare e mai bine.")
# Detectare cot È™i silhouette optim
inertia_vals = metrics['Inertia'].values
diffs = np.diff(inertia_vals)
second_diffs = np.diff(diffs)
elbow_idx = np.argmax(second_diffs) + 1
elbow_k = ks[elbow_idx]
sil_k = int(metrics.loc[metrics['Silhouette'].idxmax(), 'K'])
st.markdown(f"**Sugerat K (cot):** {elbow_k}    |    **Cel mai bun K Silhouette:** {sil_k}")
opt_k = st.slider(
    "Alege numÄƒrul optim de clustere:",
    min_value=2,
    max_value=max(ks),
    value=elbow_k,
    help="SelecteazÄƒ K bazat pe cot sau silhouette"
)

# --- Pasul 4: Clusterizare finalÄƒ & calitate ---
st.markdown("## ğŸ¯ Pasul 4: Clusterizare & Calitate")
st.markdown(
    """
    **DistribuÈ›ie Silhouette:** AfiÈ™eazÄƒ cÃ¢t de bine se potrivesc punctele Ã®n cluster.

    **Dimensiuni clustere:** NumÄƒrul de judeÈ›e per cluster.
    """
)

km_final = KMeans(n_clusters=opt_k, random_state=42, n_init=10)
labels = km_final.fit_predict(X_pca)
sil_vals = silhouette_samples(X_pca, labels)

col5, col6 = st.columns(2)
with col5:
    st.markdown("**DistribuÈ›ie Silhouette**")
    fig5, ax5 = plt.subplots(figsize=(4,2.5))
    ax5.hist(sil_vals, bins=20, edgecolor='k')
    ax5.set_xlabel('Silhouette')
    ax5.set_ylabel('NumÄƒr')
    st.pyplot(fig5)
    st.info(f"Silhouette medie: {sil_vals.mean():.3f}")
with col6:
    st.markdown("**Dimensiuni clustere**")
    fig6, ax6 = plt.subplots(figsize=(4,2.5))
    pd.Series(labels).value_counts().sort_index().plot(kind='bar', ax=ax6)
    ax6.set_xlabel('Cluster')
    ax6.set_ylabel('NumÄƒr')
    st.pyplot(fig6)
    st.info("NumÄƒrul de judeÈ›e per cluster.")

st.markdown("**ProiecÈ›ie PCA cu clustere**")
fig7, ax7 = plt.subplots(figsize=(4,3))
ax7.scatter(X_pca[:,0], X_pca[:,1], c=labels, cmap='tab10', alpha=0.7)
ax7.set_xlabel('PC1')
ax7.set_ylabel('PC2')
st.pyplot(fig7)
st.info("JudeÈ›e colorate dupÄƒ cluster Ã®n spaÈ›iul PCA.")

# --- Pasul 5: Profilare clustere ---
st.markdown("## ğŸ“Š Pasul 5: Profilare clustere")
st.markdown(
    """
    **Ce vezi:** Tabelul aratÄƒ valorile medii ale caracteristicilor pentru fiecare cluster.
    """
)
agg['Cluster'] = labels
profile = agg.groupby('Cluster')[features].mean()
st.dataframe(profile)
st.info("Tabelul afiÈ™eazÄƒ valorile medii per cluster pentru interpretare.")

# --- Pasul 6: HartÄƒ & interpretare ---
st.markdown("## ğŸ—ºï¸ Pasul 6: HartÄƒ & Interpretare")
@st.cache_data(show_spinner="Se Ã®ncarcÄƒ shapefile...")
def load_sf(path): return load_shapefile(path)
gdf = load_sf('Data/Romania1000k.shp')
col = [c for c in gdf.columns if c.lower() in ['nume','county','judet']][0]
gdf['county_clean'] = gdf[col].map(lambda x: normalize_county(x))
df_map = gdf.set_index('county_clean').join(agg.set_index('county_clean'))

m = folium.Map(location=[45.9432,24.9668], zoom_start=7, tiles='CartoDB positron')
folium.Choropleth(
    geo_data=df_map.__geo_interface__,
    data=df_map,
    columns=[col,'Cluster'],
    key_on=f'feature.properties.{col}',
    fill_color='Set3',
    fill_opacity=0.7,
    line_opacity=0.2,
    legend_name='Cluster'
).add_to(m)
folium.GeoJson(
    df_map,
    style_function=lambda x: {'color':'#444','weight':0.5,'fillOpacity':0},
    tooltip=GeoJsonTooltip(fields=[col,'Cluster'], aliases=['JudeÈ›','Cluster'])
).add_to(m)

st_folium(m, width=800, height=500)
st.info(
    "Harta aratÄƒ clusterizarea judeÈ›elor; grupuri cu caracteristici similare de elevi."
)

# --- De ce clusterizare? ---
st.markdown("### De ce clusterizare?", unsafe_allow_html=True)
st.markdown(
    """
    Am aplicat KMeans pentru a identifica judeÈ›ele cu caracteristici de elevi similare,
    sprijinind decizii locale È›intite.
    """
)

# --- Pasul 7: Concluzii & ImplicaÈ›ii practice ---
st.markdown("## ğŸ“ Concluzii & ImplicaÈ›ii practice")
st.markdown(
    """
    **ConstatÄƒri cheie:**
    - JudeÈ›ele s-au grupat Ã®n categorii distincte conform mÄƒrimii claselor È™i distribuÈ›iei elevilor.
    - JudeÈ›ele urbane tind spre clustere cu Ã®nscrieri mari È™i rate scÄƒzute de abandon.

    **ImplicaÈ›ii:**
    - Clusterele cu rate ridicate de abandon pot primi suport specific: meditaÈ›ii, investiÈ›ii Ã®n infrastructurÄƒ.
    - Compararea profilurilor clusterelor ajutÄƒ la implementarea bunelor practici.

    **UrmÄƒtorii paÈ™i:**
    1. Modelare predictivÄƒ: foloseÈ™te etichetele clusterelor pentru a prezice ratele viitoare de abandon.
    2. Alocare resurse: direcÈ›ioneazÄƒ intervenÈ›ii conform nevoilor clusterelor.
    3. Monitorizare: urmÄƒreÈ™te evoluÈ›ia clusterelor Ã®n timp pentru a evalua impactul politicilor.

    AceastÄƒ analizÄƒ oferÄƒ o bazÄƒ pentru decizii data-driven Ã®n reducerea abandonului È™colar.
    """
)
